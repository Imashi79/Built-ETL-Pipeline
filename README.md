# ğŸš€ ETL Pipelines for Data Processing  

This repository contains multiple **independent ETL (Extract, Transform, Load) pipelines**, designed to process data from various sources, including APIs, CSV, and Excel files.  

## ğŸ“ Project Structure  

Each folder represents an **independent ETL pipeline** with its own implementation:  

- ğŸ“Œ **ETL_pipeline_api/** â€“ Extracts data from an API, transforms it, and loads it into a database.  
- ğŸ“Œ **ETL_pipeline_csv_1/** â€“ Processes raw CSV files, cleans, and stores data for analysis.  
- ğŸ“Œ **ETL_pipeline_csv_2/** â€“ A variation of the CSV-based ETL pipeline with different transformation logic.  
- ğŸ“Œ **ETL_pipeline_excel/** â€“ Reads Excel files, performs data wrangling, and loads structured data.  

## ğŸ”§ Technologies Used  

- âœ… **Python** *(pandas, requests, sqlalchemy, psycopg2)*  
- âœ… **PostgreSQL** *(for structured data storage)*  
- âœ… **Jupyter Notebook** *(for development and testing)*  

## ğŸ” Overview of ETL Process  

1ï¸âƒ£ **Extract** â€“ Fetches data from APIs, CSV, or Excel sources.  
2ï¸âƒ£ **Transform** â€“ Cleans, filters, and structures the data.  
3ï¸âƒ£ **Load** â€“ Stores processed data in a PostgreSQL database for further analysis.  

## ğŸ¯ Expected Outcome  

- âœ… Well-structured, cleaned, and formatted data.  
- âœ… Scalable and modular ETL pipelines.  
- âœ… Ready-to-use datasets stored in a relational database for querying and analytics.  

---


